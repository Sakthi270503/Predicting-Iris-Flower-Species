{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2a6672-81da-420e-a270-983fc17b7c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   species  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "Shape of the dataset: (150, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   species            150 non-null    int32  \n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 5.4 KB\n",
      "None\n",
      "Missing values: sepal length (cm)    0\n",
      "sepal width (cm)     0\n",
      "petal length (cm)    0\n",
      "petal width (cm)     0\n",
      "species              0\n",
      "dtype: int64\n",
      "Unique species: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Add target (species) to the DataFrame\n",
    "iris_df['species'] = iris.target\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(iris_df.head())\n",
    "\n",
    "# Display the shape of the DataFrame\n",
    "print(\"Shape of the dataset:\", iris_df.shape)\n",
    "\n",
    "# Display information about the dataset\n",
    "print(iris_df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\", iris_df.isnull().sum())\n",
    "\n",
    "# Display unique values of the target variable (species)\n",
    "print(\"Unique species:\", iris_df['species'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605165f1-8453-4171-8146-b46ed2ba9e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = iris_df.drop('species', axis=1)\n",
    "y = iris_df['species']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features by scaling them\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86bebaf-e05f-4c19-8b5b-668aa9e21ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the scaled training data\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ab5325-97bc-4a9a-bf3b-4b87be5ee383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c685c205-9562-469a-a034-a2fa3c74ce17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes:\n",
      "setosa\n",
      "versicolor\n",
      "virginica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new, unseen data\n",
    "new_data = [[5.1, 3.5, 1.4, 0.2],  # Example iris flower features\n",
    "            [6.2, 2.9, 4.3, 1.3],\n",
    "            [7.3, 2.8, 6.4, 2.0]]\n",
    "\n",
    "# Scale the new data using the same scaler used for training\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "new_predictions = clf.predict(new_data_scaled)\n",
    "\n",
    "# Print the predicted classes\n",
    "print(\"Predicted classes:\")\n",
    "for prediction in new_predictions:\n",
    "    print(iris.target_names[prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb898c-7706-493f-ae33-ff6c35245bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
